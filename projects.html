<!DOCTYPE html>
<html>
    <head>
        <!--below, the <meta> tag defines the metadata-->
        <meta charset = "utf-8">
        <meta name = "description" content = "Jen Semler is philosopher researching artificial moral agency">
        <meta name = "author" content = "Jen Semler">
        <meta name = "keywords" content = "philosophy, AI ethics">
        <!--below: tells the browser to scale the page to the size of the device-->
        <meta name = "viewport" content = "width=device-width, initial-scale=1.0">
        <!--below is the title that shows up on the tab-->
        <title>Jen Semler | Research</title>
        <!--below is the link to favicon-->
        <link rel = "icon" type = "image/x-icon" href = "JS.png">
        <!--below is the link to the CSS sheet-->
        <link rel = "stylesheet" href = "style.css">
        <link rel = "stylesheet" href = "https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.1/css/all.min.css">
        <!--below are fonts-->
        <link href = 'https://fonts.googleapis.com/css?family=Fugaz One' rel = 'stylesheet'>
        <link href = 'https://fonts.googleapis.com/css?family=Roboto' rel = 'stylesheet'>
    </head>

    <body class = "projects">

        <nav>
            <a href = "index.html" class = logo><span>JEN SEMLER</span></a>

            <!--below creates the nav bar as a list-->
            <ul class = "links">
                <li class = "res"> <a href = "projects.html">research</a> </li>
                <li class = "pubs"> <a href = "pubs.html">publications</a> </li>
                <li class = "teach"> <a href = "teaching.html">teaching</a> </li>
                <li> <div class = "btn"><a href = "Semler_CV.pdf" target = "_blank">CV</a></div></li>
            </ul>

            <i class="fa-solid fa-bars" id = "menu"></i>

        </nav>
                
        <section id = "research">

            <div class = "research-description">
                <div><h2>Oveview</h2></div>

                <div>I work on artificial moral agency: how AI systems <i>can</i> and <i>should</i> be used in the moral domain.</div>
                
                <div>
                    My research has three strands. 
                    The <span class = "orange">theoretical</span> strand concerns the nature of moral agency (what makes an entity capable of acting morally wrongly and responsibly).
                    The <span class = "orange">applied</span> strand concerns how we should use AI in the moral domain (both in general and in specific contexts).
                    The <span class = "orange">empirical</span> strand concerns the capabilities of AI systems (technically grounded philosophy) and the ways in which humans think about moral agency (experimental philosophy).
                </div>

             <div class = "btn-box">
                    <div class = btn><a href = "https://philpeople.org/profiles/jen-semler" target = "_blank">PhilPeople</a></a></div>
                    <div class = btn><a href = "https://scholar.google.com/citations?user=VAjJy3QAAAAJ&hl=en" target = "_blank">Google Scholar</a></a></div>
                </div>

            </div>

            <div class = "wip">
                <h2>Works in Progress</h2>
                <div>Moral Agents Unlike Us</div>
                <div>Artificial Moral Behavior</div>
                <div>The Folk Concept of Moral Agency <br>(with Joanna Demaree-Cotton)</div>
                <div>Autonomy, Advice, and AI <br>(with Kyle van Oosterum)</div>
                <div>No Alignment Without Moral Agency <br>(with Helen Nissenbaum)</div>
            </div>

        </section>
        
        <script src= "script.js"></script>

    </body>



        <!--
        <main class="research-grid">

            <div class="project">
                <h2>Research Overview</h2>
                <hr>
                <p>
                    Imagine you&#39;ve been fired from your job by a reliable and competent decision-maker. 
                    This decision-maker reached their conclusion in the right way&mdash;and they can provide reasons and explanations for their decision. 
                    Does it matter who, or what, the decision-maker is? 
                    The guiding claim of my research is that it matters whether morally laden decisions are made by moral agents. 
                    My work considers what makes something a moral agent, which entities are moral agents, and why we should care about moral agency—all with a focus on AI. 
                    These questions form three interrelated research strands.
                </p>
                <p>
                    <h3>Non-Prototypical Moral Agency</h3>
                    This theoretical strand of my research concerns the nature of moral agency, with a particular focus on moral agents (and potential moral agents) beyond the prototypical adult human. 
                    Broadly, on my account, there are different types of moral agency&mdash;and while there are certain necessary conditions for each type, these conditions can be instantiated in a variety of ways. 
                </p>
                <p> 
                    <h3>Applied Ethics of Technology</h3>
                    This applied strand of my research concerns how we ought to integrate AI systems into our moral practices. 
                    The papers in this strand focus on how our use of AI in moral decision-making contexts should be limited by AI systems’ lack of moral agency. 
                <p>
                    <h3>Empirically Engaged Philosophy of Moral Agency</h3>
                    This empirical strand of my research concerns the capabilities of AI systems (empirically informed and technically grounded philosophy) and the ways in which humans think about moral agency (experimental philosophy). 
                </p>
            </div>

            <div class="project">
                <h2>Works in Progress</h2>
                <hr>
                <li><b>Moral Agents Unlike Us</b> 
                    | <a href="Semler MAUU AIES Draft.pdf" target="_blank">AIES 2025 draft</a>
                <br>I argue that moral agency isn't all that matters&mdash;even if AI systems are moral agents, they will be different from us in normatively significant ways and will thus play different roles from humans in the moral community. 
                </li>
                <li><b>Artificial Moral Behavior</b>
                <br> I argue that delegating moral decisions to AI systems is wrong because doing so replaces events that should be moral actions with mere behaviors. 
                </li>
                <div class = "btn"><a href = "https://philpeople.org/profiles/jen-semler" target = "_blank">PhilPeople</a></div>
            <div class = "btn"><a href = "https://scholar.google.com/citations?user=VAjJy3QAAAAJ&hl=en" target = "_blank">Google Scholar</a></div>
        </main> 

        <footer>
        </footer>


    </body>

</html>
