<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="description" content="Jen Semler is a graduate student in philosophy at Oxford studying AI ethics">
        <meta name="author" content="Jen Semler">
        <meta name="keywords" content="philosophy, AI ethics, Oxford">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Jen Semler | Research</title>
        <link rel="icon" type="image/x-icon" href="favicon.ico">
        <link rel="stylesheet" href="style.css">
        <link href='https://fonts.googleapis.com/css?family=Manrope' rel='stylesheet'>
        <style>
            body {font-family: 'Inter'}
        </style>

    <body>
        <header>
            <h1><a href ="index.html" class="logo">JEN SEMLER</a></h1>
            <input type="checkbox" id="nav-toggle" class="nav-toggle">
            <nav>
                <ul>
                    <li><a href="projects.html">research</a></li>
                    <li><a href="pubs.html">publications</a></li>
                    <li><a href="Semler_CV.pdf" target="_blank">CV</a></li>
                </ul>
            </nav>
            <label for="nav-toggle" class="nav-toggle-label">
                <span></span>
            </label>
                   
        </header>

        <main class="research-grid">

            <div class="project">
                <h2>Research Overview</h2>
                <hr>
                <p>
                    Imagine you&#39;ve been fired from your job by a reliable and competent decision-maker. 
                    This decision-maker reached their conclusion in the right way&mdash;and they can provide reasons and explanations for their decision. 
                    Does it matter who, or what, the decision-maker is? 
                    The guiding claim of my research is that it matters whether morally laden decisions are made by moral agents. 
                    My work considers what makes something a moral agent, which entities are moral agents, and why we should care about moral agency—all with a focus on AI. 
                    These questions form three interrelated research strands.
                </p>
                <p>
                    <h3>Non-Prototypical Moral Agency</h3>
                    This theoretical strand of my research concerns the nature of moral agency, with a particular focus on moral agents (and potential moral agents) beyond the prototypical adult human. 
                    Broadly, on my account, there are different types of moral agency&mdash;and while there are certain necessary conditions for each type, these conditions can be instantiated in a variety of ways. 
                </p>
                <p> 
                    <h3>Applied Ethics of Technology</h3>
                    This applied strand of my research concerns how we ought to integrate AI systems into our moral practices. 
                    The papers in this strand focus on how our use of AI in moral decision-making contexts should be limited by AI systems’ lack of moral agency. 
                <p>
                    <h3>Empirically Engaged Philosophy of Moral Agency</h3>
                    This empirical strand of my research concerns the capabilities of AI systems (empirically informed and technically grounded philosophy) and the ways in which humans think about moral agency (experimental philosophy). 
                </p>
            </div>

            <div class="project">
                <h2>Works in Progress</h2>
                <hr>
                <li><b>Moral Agents Unlike Us</b> 
                    | <a href="Semler MAUU AIES Draft.pdf" target="_blank">AIES 2025 draft</a>
                <br>I argue that moral agency isn't all that matters&mdash;even if AI systems are moral agents, they will be different from us in normatively significant ways and will thus play different roles from humans in the moral community. 
                </li>
                <li><b>Artificial Moral Behavior</b>
                <br> I argue that delegating moral decisions to AI systems is wrong because doing so replaces events that should be moral actions with mere behaviors. 
                </li>

        </main> 

        <footer>
        </footer>


    </body>

</html>
