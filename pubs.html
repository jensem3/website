<!DOCTYPE html>
<html>
    <head>
        <!--below, the <meta> tag defines the metadata-->
        <meta charset = "utf-8">
        <meta name = "description" content = "Jen Semler is philosopher researching artificial moral agency">
        <meta name = "author" content = "Jen Semler">
        <meta name = "keywords" content = "philosophy, AI ethics">
        <!--below: tells the browser to scale the page to the size of the device-->
        <meta name = "viewport" content = "width=device-width, initial-scale=1.0">
        <!--below is the title that shows up on the tab-->
        <title>Jen Semler | Publications</title>
        <!--below is the link to favicon-->
        <link rel = "icon" type = "image/x-icon" href = "JS.png">
        <!--below is the link to the CSS sheet-->
        <link rel = "stylesheet" href = "style.css">
        <link rel = "stylesheet" href = "https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.1/css/all.min.css">
        <!--below are fonts-->
        <link href = 'https://fonts.googleapis.com/css?family=Fugaz One' rel = 'stylesheet'>
        <link href = 'https://fonts.googleapis.com/css?family=Roboto' rel = 'stylesheet'>
    </head>

    <body class = "publications">

        <nav>
            <a href = "index.html" class = logo><span>JEN SEMLER</span></a>

            <!--below creates the nav bar as a list-->
            <ul class = "links">
                <li class = "res"> <a href = "projects.html">research</a> </li>
                <li class = "pubs"> <a href = "pubs.html">publications</a> </li>
                <li class = "teach"> <a href = "teaching.html">teaching</a> </li>
                <li> <div class = "btn"><a href = "Semler_CV.pdf" target = "_blank">CV</a></div></li>
            </ul>

            <i class="fa-solid fa-bars" id = "menu"></i>

        </nav>

        <section id = "papers">
            <div class = "paper-box">
                <div><h3>Moral Agency Without Consciousness</h3></div>
                <div><i>Canadian Journal of Philosophy (2025)</i></div>
                <div><strong>Abstract:</strong><br>Many views of moral agency include, implicitly or explicitly, a consciousness requirement—namely, the claim that phenomenal consciousness is a necessary condition of moral agency. This paper casts doubt on the consciousness requirement. I argue that consciousness is not necessary for instantiating four key capacities necessary for moral agency: action, moral concept possession, responsiveness to moral reasons, and moral understanding. I defend my picture of nonconscious moral agency as a plausible account of an entity that can act for moral reasons and can be morally responsible. Lastly, I discuss broader implications of my argument, especially on the possibility of artificial moral agency.</div>

                <div class = "btn-box">
                    <div class = btn><a href = "https://philpapers.org/archive/SEMMAW.pdf" target = "_blank">penultimate draft</a></a></div>
                    <div class = btn><a href = "https://doi.org/10.1017/can.2025.10008" target = "_blank">published version</a></a></div>
                    <div class = btn><a href = "https://newworkinphilosophy.substack.com/p/moral-agency-without-consciousness" target = "_blank">NWIP Blog Post</a></a></div>
                </div>

            </div>
            
            <div class = "paper-box">
                <div><h3>A Timing Problem for Instrumental Convergence</h3></div>
                <div>with Helena Ward & Rhys Southan</div>
                <div><i>Philosophical Studies (2025)</i></div>
                <div><strong>Abstract:</strong><br>Those who worry about a superintelligent AI destroying humanity often appeal to the instrumental convergence thesis—the claim that even if we don’t know what a superintelligence’s ultimate goals will be, we can expect it to pursue various instrumental goals which are useful for achieving most ends. In this paper, we argue that one of these proposed goals is mistaken. We argue that instrumental goal preservation—the claim that a rational agent will tend to preserve its goals because that makes it better at achieving its goals—is false on the basis of the timing problem: an agent which abandons or otherwise changes its goal does not thereby fail to take a required means for achieving a goal it has. Our argument draws on the distinction between means-rationality (adopting suitable means to achieve an end) and ends-rationality (choosing one’s ends based on reasons). Because proponents of the instrumental convergence thesis are concerned with means-rationality, we argue, they cannot avoid the timing problem. After defending our argument against several objections, we conclude by considering the implications our argument has for the rest of the instrumental convergence thesis and for AI safety more generally.</div>
                <div class = "btn-box">
                    <div class = btn><a href = "https://doi.org/10.1007/s11098-025-02370-4" target = "_blank">published version</a></a></div>
                    <div class = btn><a href = "https://newworkinphilosophy.substack.com/p/a-timing-problem-for-instrumental" target = "_blank">NWIP Blog Post</a></a></div>
                    <div class = btn><a href = "https://reflectivealtruism.com/2025/08/22/papers-i-learned-from-part-6-a-timing-problem-for-instrumental-convergence/" target = "_blank">Reflective Altruism Blog Post</a></a></div>
                </div>
            </div>

            <div class = "paper-box">
                <div><h3>Recent Experimental Work on 'Ought' Implies 'Can'</h3></div>
                <div>with Paul Henne</div>
                <div><i>Philosophy Compass (2019)</i></div>
                <div><strong>Abstract:</strong><br>While philosophers generally accept some version of the principle “ought” implies “can,” recent work in experimental philosophy and cognitive science provides evidence against a presupposition or a conceptual entailment from “ought” to “can.” Here, we review some of this evidence, its effect on particular formulations of the principle, and future directions for cognitive scientists and philosophers.</div>
                <div class = "btn-box">
                    <div class = btn><a href = "https://doi.org/10.1111/phc3.12619" target = "_blank">published version</a></a></div>
                </div>
            </div>

             <div class = "paper-box">
                <div><h3>Against some Recent Arguments for 'Ought' Implies 'Can': Reasons, Deliberation, Trying, and Furniture</h3></div>
                <div>with Paul Henne, Vlad Chituc, Felipe De Brigard, & Walter Sinnott-Armstrong</div>
                <div><i>Philosophia (2019)</i></div>
                <div><strong>Abstract:</strong><br>Many philosophers claim that ‘ought’ implies ‘can’. In light of recent empirical evidence, however, some skeptics conclude that philosophers should stop assuming the principle unconditionally. Streumer, however, does not simply assume the principle’s truth; he provides arguments for it. In this article, we argue that his arguments fail to support the claim that ‘ought’ implies ‘can’.</div>
                <div class = "btn-box">
                    <div class = btn><a href = "https://doi.org/10.1007/s11406-017-9944-7" target = "_blank">published version</a></a></div>
                </div>
            </div>

        </section>

         <!--
        <main class="pubs">
               
           <h2>Journal Articles</h2>
           <p>
                <b>Moral Agency Without Consciousness</b>
                | <a href="https://philpapers.org/archive/SEMMAW.pdf" target="_blank">penultimate draft</a>
                | <a href="https://doi.org/10.1017/can.2025.10008" target="_blank">published version</a>
                <br><em>Canadian Journal of Philosophy</em> (2025)
                <br>Summary available on the <a href="https://newworkinphilosophy.substack.com/p/moral-agency-without-consciousness" target="blank">New Work in Philosophy Blog</a>
            </p>
             <p>
                <b>A Timing Problem for Instrumental Convergence</b>
                | <a href="https://doi.org/10.1007/s11098-025-02370-4" target="_blank">published version</a>
                <br>with Helena Ward and Rhys Southan
                <br><em>Philosophical Studies</em> (2025)
                <br>Summaries available on the <a href="https://reflectivealtruism.com/2025/08/22/papers-i-learned-from-part-6-a-timing-problem-for-instrumental-convergence/" target="blank">Reflective Altruism Blog</a> 
                and the <a href="https://newworkinphilosophy.substack.com/p/a-timing-problem-for-instrumental" target="blank">New Work in Philosophy Blog</a>
            </p>
            <p>
                <b>Recent Experimental Work on &#39;Ought&#39; Implies &#39;Can&#39;</b>
                | <a href="https://doi.org/10.1111/phc3.12619" target="_blank">published version</a> 
                <br>with Paul Henne
                <br><em>Philosophy Compass</em> (2019)
            </p>
            <p>
                    <b>Against some Recent Arguments for &#39;Ought&#39; Implies &#39;Can&#39;: Reasons, Deliberation, Trying, and Furniture</b>
                    | <a href="https://doi.org/10.1007/s11406-017-9944-7" target="_blank">published version</a> 
                    <br>with Paul Henne, Vlad Chituc, Felipe De Brigard, & Walter Sinnott-Armstrong
                    <br><em>Philosophia</em> (2019)
                </p>
                <h2>DPhil (PhD) Dissertation</h2>
                <p>
                    <b>On Artificial Moral Agency</b>
                    | <a href="Dissertation_Abstract.pdf" target="_blank">abstract</a>
                    <br>University of Oxford (2025)
                </p>
                <h2>Textbook Contributions</h2>
                <p>
                    <b>Corporate Human Rights Obligations</b> (forthcoming)
                    <br>case study for the<q>Human Rights</q> chapter in <em>Issues in Political Theory</em>, edited by Robert Jubb & Patrick Tomlin, Oxford University Press
                </p>
                <p>
                    <b>Lockdowns</b> (forthcoming)
                    <br>case study for the<q>Liberty</q> chapter in <em>Issues in Political Theory</em>, edited by Robert Jubb & Patrick Tomlin, Oxford University Press
                </p>
            </div>

        </main> 
            -->
        <script src= "script.js"></script>

    </body>
</html>
